{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv_path = (\"/Users/maukanmir/Documents/Machine-Learning/Web-Scraping-Code/Player-Salaries/dot.env\")\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\")\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "TABLE_NAME = \"team_salaries\"\n",
    "\n",
    "engine = create_engine(f'postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}/{DB_NAME}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_player_info(html_content, year):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    player_data = []\n",
    "    players = soup.find_all('li', class_='list-group-item')\n",
    "\n",
    "    for player in players:\n",
    "        data = {}\n",
    "\n",
    "        name_div = player.find('div', class_='link')\n",
    "        salary_span = player.find('span', class_='medium')\n",
    "        team_position_small = player.find('small')\n",
    "        \n",
    "        if name_div:\n",
    "            \n",
    "            data['player'] = name_div.text.strip()\n",
    "\n",
    "            block = team_position_small.text.strip().split(\",\")\n",
    "            team = block[0]\n",
    "            pos = block[1]\n",
    "            data['team'] = team\n",
    "            data[\"pos\"] = pos\n",
    "            salary = salary_span.text.strip().replace(\"$\", \"\").replace(\",\", \"\")\n",
    "            data['salary'] = int(salary)\n",
    "            player_data.append(data)\n",
    "    \n",
    "    df = pd.DataFrame(player_data)\n",
    "    df[\"season\"] = int(year)\n",
    "    return df\n",
    "\n",
    "def extract_team_info(html_content, year):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    tds = soup.findAll(\"td\")\n",
    "    stats = [td.text.strip() for td in tds]\n",
    "    sep_blocks = \" \".join(stats).split(\".\")[1:]\n",
    "    teams_salaries = [block.strip().split(\" \")[:4] for block in sep_blocks]\n",
    "    \n",
    "    df = []\n",
    "    for block in teams_salaries:\n",
    "        teams = {}\n",
    "        for idx, part in enumerate(block):\n",
    "            if \"$\" in part and block[idx-1].isalpha():\n",
    "                integer = part.replace(\"$\", \"\").replace(\",\", \"\")\n",
    "                teams[\"salary\"] = int(integer)\n",
    "            elif part.isalpha():\n",
    "                if block[idx+1].isalpha():\n",
    "                    teams[\"Team\"] = part + \" \" + block[idx+1]\n",
    "                    df.append(teams)\n",
    "                elif not block[idx+1].isalpha() and not block[idx-1].isalpha():\n",
    "                    teams[\"Team\"] = part\n",
    "                    df.append(teams)\n",
    "    \n",
    "    master_df= pd.DataFrame(df)\n",
    "    master_df[\"season\"] = year\n",
    "    return master_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grabbing Player Salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [str(year) for year in range(2011, 2025)]\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "for year in years:\n",
    "  url = f\"https://www.spotrac.com/nba/rankings/player/_/year/{year}/sort/cash_total\"\n",
    "  response = requests.get(url)\n",
    "  df = extract_player_info(response.text, year)\n",
    "  all_data = pd.concat([all_data, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['id'] = range(1, len(all_data) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save To Posgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to the database.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  with psycopg2.connect(\n",
    "        host=DB_HOST,\n",
    "        database=DB_NAME,\n",
    "        user=DB_USER,\n",
    "        password=DB_PASSWORD\n",
    "    ) as conn:\n",
    "      with conn.cursor(cursor_factory=psycopg2.extras.DictCursor) as cur:\n",
    "        cur.execute(f\"DROP TABLE IF EXISTS {TABLE_NAME};\")\n",
    "\n",
    "        cur.execute(f\"\"\"\n",
    "            CREATE TABLE {TABLE_NAME} (\n",
    "                id INTEGER PRIMARY KEY,\n",
    "                player VARCHAR(255),\n",
    "                team VARCHAR(12),\n",
    "                pos  VARCHAR(20),\n",
    "                salary INTEGER,\n",
    "                season INTEGER\n",
    "            );\n",
    "        \"\"\")\n",
    "        \n",
    "        insert_query = f'INSERT INTO {TABLE_NAME} (id, player, team, pos, salary, season) VALUES (%s, %s, %s, %s, %s, %s)'\n",
    "        rows_to_insert = [(row[\"id\"], row['player'], row['team'], row['pos'], row['salary'], row['season']) for index, row in all_data.iterrows()]\n",
    "        cur.executemany(insert_query, rows_to_insert)\n",
    "        \n",
    "        conn.commit()\n",
    "        print(\"Data written to the database.\")\n",
    "except Exception as e:\n",
    "  print(f\"Database Failed to upload Data. The error is: {e}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBA Team Salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [str(year) + \"-\" + str(year+1) for year in range(1990, 2024)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.DataFrame()\n",
    "for year in years:\n",
    "  base_url = f\"https://hoopshype.com/salaries/{year}/\"\n",
    "  response = requests.get(url)\n",
    "  df = extract_team_info(response.text, year)\n",
    "  all_data = pd.concat([all_data, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_team_abbreivated = {\n",
    "  \"Atlanta\":\"ATL\",\n",
    "  \"Cleveland\": \"CLE\",\n",
    "  \"New York\": \"NYK\",\n",
    "  \"Charlotte\": \"CHA\",\n",
    "  \"Detroit\": \"DET\",\n",
    "  \"Dallas\": \"DAL\",\n",
    "  \"Philadelphia\": \"PHI\",\n",
    "  \"Milwaukee\": \"MIL\",\n",
    "  \"Phoenix\":\"PHX\",\n",
    "  \"Brooklyn\":\"BKN\",\n",
    "  \"Boston\":\"BOS\",\n",
    "  \"Portland\":\"POR\",\n",
    "  \"Golden State\":\"GSW\",\n",
    "  \"San Antonio\":\"SAS\",\n",
    "  \"Indiana\":\"IND\",\n",
    "  \"Utah\":\"UT\",\n",
    "  \"Oklahoma City\":\"OKC\",\n",
    "  \"Houston\":\"HOU\",\n",
    "  \"Denver\":\"DEN\",\n",
    "  \"LA Clippers\":\"LAC\",\n",
    "  \"Chicago\":\"CHI\",\n",
    "  \"Washington\":\"WAS\",\n",
    "  \"Sacramento\":\"SAC\",\n",
    "  \"Miami\":\"MIA\",\n",
    "  \"Minnesota\":\"MIN\",\n",
    "  \"Orlando\":\"ORL\",\n",
    "  \"New Orleans\":\"NOP\",\n",
    "  \"Memphis\":\"MEM\",\n",
    "  \"Toronto\":\"TOR\",\n",
    "  \"LA Lakers\":\"LAL\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"Team\"] = all_data[\"Team\"].apply(lambda x: nba_team_abbreivated[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Dataset into DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to the database.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    all_data.to_sql(TABLE_NAME, engine, if_exists='replace', index=False)\n",
    "    print(\"Data successfully written to the database.\")\n",
    "except Exception as e:\n",
    "    print(f\"Database operation failed. Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_url = f\"https://hoopshype.com/salaries/2023-2024/\"\n",
    "response = requests.get(base_url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "tds = soup.findAll(\"td\")\n",
    "stats = [td.text.strip() for td in tds]\n",
    "sep_blocks = \" \".join(stats).split(\".\")[1:]\n",
    "teams_salaries = [block.strip().split(\" \")[:4] for block in sep_blocks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Team': 'Golden State', 'salary': 209354737},\n",
       " {'Team': 'LA Clippers', 'salary': 201366679},\n",
       " {'Team': 'Phoenix', 'salary': 193838882},\n",
       " {'Team': 'Milwaukee', 'salary': 187346674},\n",
       " {'Team': 'Boston', 'salary': 186940921},\n",
       " {'Team': 'Denver', 'salary': 180922992},\n",
       " {'Team': 'Miami', 'salary': 177143542},\n",
       " {'Team': 'LA Lakers', 'salary': 169876920},\n",
       " {'Team': 'Dallas', 'salary': 167755884},\n",
       " {'Team': 'New Orleans', 'salary': 167403924},\n",
       " {'Team': 'Cleveland', 'salary': 166874287},\n",
       " {'Team': 'Minnesota', 'salary': 166434327},\n",
       " {'Team': 'Philadelphia', 'salary': 166271894},\n",
       " {'Team': 'Chicago', 'salary': 165630436},\n",
       " {'Team': 'Portland', 'salary': 165263993},\n",
       " {'Team': 'New York', 'salary': 164990518},\n",
       " {'Team': 'Toronto', 'salary': 163054678},\n",
       " {'Team': 'Memphis', 'salary': 162649524},\n",
       " {'Team': 'Oklahoma City', 'salary': 162515272},\n",
       " {'Team': 'Atlanta', 'salary': 159153393},\n",
       " {'Team': 'Brooklyn', 'salary': 155015136},\n",
       " {'Team': 'Sacramento', 'salary': 153564021},\n",
       " {'Team': 'Washington', 'salary': 150856313},\n",
       " {'Team': 'Houston', 'salary': 149356730},\n",
       " {'Team': 'Indiana', 'salary': 148722330},\n",
       " {'Team': 'San Antonio', 'salary': 142867770},\n",
       " {'Team': 'Detroit', 'salary': 139233014},\n",
       " {'Team': 'Charlotte', 'salary': 135774484},\n",
       " {'Team': 'Utah', 'salary': 133738448},\n",
       " {'Team': 'Orlando', 'salary': 132643598}]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = []\n",
    "for block in teams_salaries:\n",
    "        teams = {}\n",
    "        for idx, part in enumerate(block):\n",
    "            if \"$\" in part and block[idx-1].isalpha():\n",
    "                integer = part.replace(\"$\", \"\").replace(\",\", \"\")\n",
    "                teams[\"salary\"] = int(integer)\n",
    "            elif part.isalpha():\n",
    "                if block[idx+1].isalpha():\n",
    "                    teams[\"Team\"] = part + \" \" + block[idx+1]\n",
    "                    df.append(teams)\n",
    "                elif not block[idx+1].isalpha() and not block[idx-1].isalpha():\n",
    "                    teams[\"Team\"] = part\n",
    "                    df.append(teams)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
