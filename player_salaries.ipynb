{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv_path = (\"/Users/maukanmir/Documents/Machine-Learning/Web-Scraping-Code/Player-Salaries/dot.env\")\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\")\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "TABLE_NAME = \"player_salaries\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_player_info(html_content, year):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    player_data = []\n",
    "    players = soup.find_all('li', class_='list-group-item')\n",
    "\n",
    "    for player in players:\n",
    "        data = {}\n",
    "\n",
    "        name_div = player.find('div', class_='link')\n",
    "        salary_span = player.find('span', class_='medium')\n",
    "        team_position_small = player.find('small')\n",
    "        \n",
    "        if name_div:\n",
    "            \n",
    "            data['player'] = name_div.text.strip()\n",
    "\n",
    "            block = team_position_small.text.strip().split(\",\")\n",
    "            team = block[0]\n",
    "            pos = block[1]\n",
    "            data['team'] = team\n",
    "            data[\"pos\"] = pos\n",
    "            salary = salary_span.text.strip().replace(\"$\", \"\").replace(\",\", \"\")\n",
    "            data['salary'] = int(salary)\n",
    "            player_data.append(data)\n",
    "    \n",
    "    df = pd.DataFrame(player_data)\n",
    "    df[\"season\"] = int(year)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grabbing Player Salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [str(year) for year in range(2011, 2025)]\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "for year in years:\n",
    "  url = f\"https://www.spotrac.com/nba/rankings/player/_/year/{year}/sort/cash_total\"\n",
    "  response = requests.get(url)\n",
    "  df = extract_player_info(response.text, year)\n",
    "  all_data = pd.concat([all_data, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['id'] = range(1, len(all_data) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save To Posgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to the database.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  with psycopg2.connect(\n",
    "        host=DB_HOST,\n",
    "        database=DB_NAME,\n",
    "        user=DB_USER,\n",
    "        password=DB_PASSWORD\n",
    "    ) as conn:\n",
    "      with conn.cursor(cursor_factory=psycopg2.extras.DictCursor) as cur:\n",
    "        cur.execute(f\"DROP TABLE IF EXISTS {TABLE_NAME};\")\n",
    "\n",
    "        cur.execute(f\"\"\"\n",
    "            CREATE TABLE {TABLE_NAME} (\n",
    "                id INTEGER PRIMARY KEY,\n",
    "                player VARCHAR(255),\n",
    "                team VARCHAR(12),\n",
    "                pos  VARCHAR(20),\n",
    "                salary INTEGER,\n",
    "                season INTEGER\n",
    "            );\n",
    "        \"\"\")\n",
    "        \n",
    "        insert_query = f'INSERT INTO {TABLE_NAME} (id, player, team, pos, salary, season) VALUES (%s, %s, %s, %s, %s, %s)'\n",
    "        rows_to_insert = [(row[\"id\"], row['player'], row['team'], row['pos'], row['salary'], row['season']) for index, row in all_data.iterrows()]\n",
    "        cur.executemany(insert_query, rows_to_insert)\n",
    "        \n",
    "        conn.commit()\n",
    "        print(\"Data written to the database.\")\n",
    "except Exception as e:\n",
    "  print(f\"Database Failed to upload Data. The error is: {e}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"https://hoopshype.com/salaries/players/1990-1991/\"\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "soup.findAll(\"td\", class_=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"https://hoopshype.com/salaries/1990-1991/\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tds = soup.findAll(\"td\")\n",
    "stats = [td.text.strip() for td in tds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['', 'Cleveland', '$14,403,000', '$33,829,743'],\n",
       " ['', 'New', 'York', '$13,290,000'],\n",
       " ['', 'Detroit', '$12,910,000', '$30,322,989'],\n",
       " ['', 'LA', 'Lakers', '$12,120,000'],\n",
       " ['', 'Atlanta', '$11,761,000', '$27,624,220'],\n",
       " ['', 'Dallas', '$11,693,000', '$27,464,500'],\n",
       " ['', 'Philadelphia', '$11,640,000', '$27,340,013'],\n",
       " ['', 'Milwaukee', '$11,595,000', '$27,234,318'],\n",
       " ['', 'Phoenix', '$11,463,000', '$26,924,276'],\n",
       " ['', 'Brooklyn', '$11,410,000', '$26,799,790'],\n",
       " ['', 'Boston', '$11,256,000', '$26,438,074'],\n",
       " ['', 'Portland', '$11,215,000', '$26,341,775'],\n",
       " ['', 'Golden', 'State', '$11,150,000'],\n",
       " ['', 'San', 'Antonio', '$11,057,000'],\n",
       " ['', 'Indiana', '$10,981,000', '$25,792,156'],\n",
       " ['', 'Utah', '$10,695,000', '$25,120,399'],\n",
       " ['', 'Oklahoma', 'City', '$10,590,000'],\n",
       " ['', 'Houston', '$10,500,000', '$24,662,383'],\n",
       " ['', 'Charlotte', '$10,417,000', '$24,467,433'],\n",
       " ['', 'Denver', '$10,335,000', '$24,274,832'],\n",
       " ['', 'LA', 'Clippers', '$10,245,000'],\n",
       " ['', 'Chicago', '$10,040,000', '$23,581,937'],\n",
       " ['', 'Washington', '$9,610,000', '$22,571,952'],\n",
       " ['', 'Sacramento', '$9,605,000', '$22,560,207'],\n",
       " ['', 'Miami', '$8,510,000', '$19,988,272'],\n",
       " ['', 'Minnesota', '$7,540,000', '$17,709,938'],\n",
       " ['', 'Orlando', '$7,532,000', '$17,691,149']]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sep_blocks = \" \".join(stats).split(\".\")[1:]\n",
    "[block.split(\" \")[:4] for block in sep_blocks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.',\n",
       " '2.',\n",
       " '3.',\n",
       " '4.',\n",
       " '5.',\n",
       " '6.',\n",
       " '7.',\n",
       " '8.',\n",
       " '9.',\n",
       " '10.',\n",
       " '11.',\n",
       " '12.',\n",
       " '13.',\n",
       " '14.',\n",
       " '15.',\n",
       " '16.',\n",
       " '17.',\n",
       " '18.',\n",
       " '19.',\n",
       " '20.',\n",
       " '21.',\n",
       " '22.',\n",
       " '23.',\n",
       " '24.',\n",
       " '25.',\n",
       " '26.',\n",
       " '27.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [block for block in stats if block.endswith(\".\")]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
