{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv_path = (\"/Users/maukanmir/Documents/Machine-Learning/Web-Scraping-Code/Player-Salaries/dot.env\")\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\")\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "TABLE_NAME = \"player_salaries\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_player_info(html_content, year):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    player_data = []\n",
    "    players = soup.find_all('li', class_='list-group-item')\n",
    "\n",
    "    for player in players:\n",
    "        data = {}\n",
    "\n",
    "        name_div = player.find('div', class_='link')\n",
    "        salary_span = player.find('span', class_='medium')\n",
    "        team_position_small = player.find('small')\n",
    "        \n",
    "        if name_div:\n",
    "            \n",
    "            data['player'] = name_div.text.strip()\n",
    "\n",
    "            block = team_position_small.text.strip().split(\",\")\n",
    "            team = block[0]\n",
    "            pos = block[1]\n",
    "            data['team'] = team\n",
    "            data[\"pos\"] = pos\n",
    "            salary = salary_span.text.strip().replace(\"$\", \"\").replace(\",\", \"\")\n",
    "            data['salary'] = int(salary)\n",
    "            player_data.append(data)\n",
    "    \n",
    "    df = pd.DataFrame(player_data)\n",
    "    df[\"season\"] = int(year)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grabbing Player Salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [str(year) for year in range(2011, 2025)]\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "for year in years:\n",
    "  url = f\"https://www.spotrac.com/nba/rankings/player/_/year/{year}/sort/cash_total\"\n",
    "  response = requests.get(url)\n",
    "  df = extract_player_info(response.text, year)\n",
    "  all_data = pd.concat([all_data, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['id'] = range(1, len(all_data) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save To Posgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to the database.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  with psycopg2.connect(\n",
    "        host=DB_HOST,\n",
    "        database=DB_NAME,\n",
    "        user=DB_USER,\n",
    "        password=DB_PASSWORD\n",
    "    ) as conn:\n",
    "      with conn.cursor(cursor_factory=psycopg2.extras.DictCursor) as cur:\n",
    "        cur.execute(f\"DROP TABLE IF EXISTS {TABLE_NAME};\")\n",
    "\n",
    "        cur.execute(f\"\"\"\n",
    "            CREATE TABLE {TABLE_NAME} (\n",
    "                id INTEGER PRIMARY KEY,\n",
    "                player VARCHAR(255),\n",
    "                team VARCHAR(12),\n",
    "                pos  VARCHAR(20),\n",
    "                salary INTEGER,\n",
    "                season INTEGER\n",
    "            );\n",
    "        \"\"\")\n",
    "        \n",
    "        insert_query = f'INSERT INTO {TABLE_NAME} (id, player, team, pos, salary, season) VALUES (%s, %s, %s, %s, %s, %s)'\n",
    "        rows_to_insert = [(row[\"id\"], row['player'], row['team'], row['pos'], row['salary'], row['season']) for index, row in all_data.iterrows()]\n",
    "        cur.executemany(insert_query, rows_to_insert)\n",
    "        \n",
    "        conn.commit()\n",
    "        print(\"Data written to the database.\")\n",
    "except Exception as e:\n",
    "  print(f\"Database Failed to upload Data. The error is: {e}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"https://hoopshype.com/salaries/players/1990-1991/\"\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "soup.findAll(\"td\", class_=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"https://hoopshype.com/salaries/1990-1991/\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tds = soup.findAll(\"td\")\n",
    "stats = [td.text.strip() for td in tds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_blocks = \" \".join(stats).split(\".\")[1:]\n",
    "teams_salaries = [block.strip().split(\" \")[:4] for block in sep_blocks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Cleveland', '$14,403,000', '$33,829,743', '2'],\n",
       " ['New', 'York', '$13,290,000', '$31,215,535'],\n",
       " ['Detroit', '$12,910,000', '$30,322,989', '4']]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teams_salaries[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "for salary in teams_salaries:\n",
    "  teams = {}\n",
    "  for idx, part in enumerate(salary):\n",
    "    part = part.replace(\"$\", \"\").replace(\",\", \"\")\n",
    "    if part.isalpha():\n",
    "      if salary[idx+1].isalpha():\n",
    "        teams[\"Team\"] = part + \" \" + salary[idx+1]\n",
    "      elif not salary[idx+1].isalpha() and not salary[idx-1].isalpha():\n",
    "        teams[\"Team\"] = part\n",
    "    elif part.isnumeric() and salary[idx-1].isalpha():\n",
    "      teams[\"salary\"] = part\n",
    "    if teams and teams not in df:\n",
    "        df.append(teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Team': 'Cleveland', 'salary': '14403000'},\n",
       " {'Team': 'New York', 'salary': '13290000'},\n",
       " {'Team': 'Detroit', 'salary': '12910000'},\n",
       " {'Team': 'LA Lakers', 'salary': '12120000'},\n",
       " {'Team': 'Atlanta', 'salary': '11761000'},\n",
       " {'Team': 'Dallas', 'salary': '11693000'},\n",
       " {'Team': 'Philadelphia', 'salary': '11640000'},\n",
       " {'Team': 'Milwaukee', 'salary': '11595000'},\n",
       " {'Team': 'Phoenix', 'salary': '11463000'},\n",
       " {'Team': 'Brooklyn', 'salary': '11410000'},\n",
       " {'Team': 'Boston', 'salary': '11256000'},\n",
       " {'Team': 'Portland', 'salary': '11215000'},\n",
       " {'Team': 'Golden State', 'salary': '11150000'},\n",
       " {'Team': 'San Antonio', 'salary': '11057000'},\n",
       " {'Team': 'Indiana', 'salary': '10981000'},\n",
       " {'Team': 'Utah', 'salary': '10695000'},\n",
       " {'Team': 'Oklahoma City', 'salary': '10590000'},\n",
       " {'Team': 'Houston', 'salary': '10500000'},\n",
       " {'Team': 'Charlotte', 'salary': '10417000'},\n",
       " {'Team': 'Denver', 'salary': '10335000'},\n",
       " {'Team': 'LA Clippers', 'salary': '10245000'},\n",
       " {'Team': 'Chicago', 'salary': '10040000'},\n",
       " {'Team': 'Washington', 'salary': '9610000'},\n",
       " {'Team': 'Sacramento', 'salary': '9605000'},\n",
       " {'Team': 'Miami', 'salary': '8510000'},\n",
       " {'Team': 'Minnesota', 'salary': '7540000'},\n",
       " {'Team': 'Orlando', 'salary': '7532000'}]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
