{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv_path = (\"/Users/maukanmir/Documents/Machine-Learning/Web-Scraping-Code/Player-Salaries/dot.env\")\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\")\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "TABLE_NAME_PlAYER_SALARIES = \"player_salaries\"\n",
    "TABLE_NAME_TEAM_SALARIES = \"team_salaries\"\n",
    "\n",
    "engine = create_engine(f'postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}/{DB_NAME}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_player_info(html_content, year):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    player_data = []\n",
    "    players = soup.find_all('li', class_='list-group-item')\n",
    "\n",
    "    for player in players:\n",
    "        data = {}\n",
    "\n",
    "        name_div = player.find('div', class_='link')\n",
    "        salary_span = player.find('span', class_='medium')\n",
    "        team_position_small = player.find('small')\n",
    "        \n",
    "        if name_div:\n",
    "            \n",
    "            data['player'] = name_div.text.strip()\n",
    "\n",
    "            block = team_position_small.text.strip().split(\",\")\n",
    "            team = block[0]\n",
    "            pos = block[1]\n",
    "            data['team'] = team\n",
    "            data[\"pos\"] = pos\n",
    "            salary = salary_span.text.strip().replace(\"$\", \"\").replace(\",\", \"\")\n",
    "            data['salary'] = int(salary)\n",
    "            player_data.append(data)\n",
    "    \n",
    "    df = pd.DataFrame(player_data)\n",
    "    df[\"season\"] = str(year) + \"-\" + str(year+1)\n",
    "    return df\n",
    "\n",
    "def extract_team_info(html_content, year):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    tds = soup.findAll(\"td\")\n",
    "    stats = [td.text.strip() for td in tds]\n",
    "    sep_blocks = \" \".join(stats).split(\".\")[1:]\n",
    "    teams_salaries = [block.strip().split(\" \")[:4] for block in sep_blocks]\n",
    "    \n",
    "    df = []\n",
    "    for block in teams_salaries:\n",
    "        teams = {}\n",
    "        for idx, part in enumerate(block):\n",
    "            if \"$\" in part and block[idx-1].isalpha():\n",
    "                integer = part.replace(\"$\", \"\").replace(\",\", \"\")\n",
    "                teams[\"salary\"] = int(integer)\n",
    "            elif part.isalpha():\n",
    "                if block[idx+1].isalpha():\n",
    "                    teams[\"Team\"] = part + \" \" + block[idx+1]\n",
    "                    df.append(teams)\n",
    "                elif not block[idx+1].isalpha() and not block[idx-1].isalpha():\n",
    "                    teams[\"Team\"] = part\n",
    "                    df.append(teams)\n",
    "    \n",
    "    master_df= pd.DataFrame(df)\n",
    "    master_df[\"season\"] = year\n",
    "    return master_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grabbing Player Salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [str(year) for year in range(2011, 2025)]\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "for year in years:\n",
    "  url = f\"https://www.spotrac.com/nba/rankings/player/_/year/{year}/sort/cash_total\"\n",
    "  response = requests.get(url)\n",
    "  year = int(year)\n",
    "  df = extract_player_info(response.text, year)\n",
    "  all_data = pd.concat([all_data, df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save To Posgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to the database.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    all_data.to_sql(TABLE_NAME_PlAYER_SALARIES, engine, if_exists='replace', index=False)\n",
    "    print(\"Data successfully written to the database.\")\n",
    "except Exception as e:\n",
    "    print(f\"Database operation failed. Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBA Team Salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [str(year) + \"-\" + str(year+1) for year in range(1990, 2024)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.DataFrame()\n",
    "for year in years:\n",
    "  base_url = f\"https://hoopshype.com/salaries/{year}/\"\n",
    "  response = requests.get(base_url)\n",
    "  df = extract_team_info(response.text, year)\n",
    "  all_data = pd.concat([all_data, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_team_abbreivated = {\n",
    "  \"Atlanta\":\"ATL\",\n",
    "  \"Cleveland\": \"CLE\",\n",
    "  \"New York\": \"NYK\",\n",
    "  \"Charlotte\": \"CHA\",\n",
    "  \"Detroit\": \"DET\",\n",
    "  \"Dallas\": \"DAL\",\n",
    "  \"Philadelphia\": \"PHI\",\n",
    "  \"Milwaukee\": \"MIL\",\n",
    "  \"Phoenix\":\"PHX\",\n",
    "  \"Brooklyn\":\"BKN\",\n",
    "  \"Boston\":\"BOS\",\n",
    "  \"Portland\":\"POR\",\n",
    "  \"Golden State\":\"GSW\",\n",
    "  \"San Antonio\":\"SAS\",\n",
    "  \"Indiana\":\"IND\",\n",
    "  \"Utah\":\"UT\",\n",
    "  \"Oklahoma City\":\"OKC\",\n",
    "  \"Houston\":\"HOU\",\n",
    "  \"Denver\":\"DEN\",\n",
    "  \"LA Clippers\":\"LAC\",\n",
    "  \"Chicago\":\"CHI\",\n",
    "  \"Washington\":\"WAS\",\n",
    "  \"Sacramento\":\"SAC\",\n",
    "  \"Miami\":\"MIA\",\n",
    "  \"Minnesota\":\"MIN\",\n",
    "  \"Orlando\":\"ORL\",\n",
    "  \"New Orleans\":\"NOP\",\n",
    "  \"Memphis\":\"MEM\",\n",
    "  \"Toronto\":\"TOR\",\n",
    "  \"LA Lakers\":\"LAL\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"Team\"] = all_data[\"Team\"].apply(lambda x: nba_team_abbreivated[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Dataset into DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to the database.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    all_data.to_sql(TABLE_NAME_TEAM_SALARIES, engine, if_exists='replace', index=False)\n",
    "    print(\"Data successfully written to the database.\")\n",
    "except Exception as e:\n",
    "    print(f\"Database operation failed. Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
